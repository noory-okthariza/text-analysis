---
title: "text-analysis: wordclout"
format: html
editor: visual
---

```{r}
# library
library(tm)
library(wordcloud) 
library(readtext)
```

```{r}
# load the files
setwd("~/Desktop/text-analysis/State of the union")
democrat <- readtext("Democrat.docx")
republic <- readtext("Republican.docx")

```

```{r}
# cleaning the files
preprocess_text <- function(text) {
  corpus <- Corpus(VectorSource(text))
  corpus <- tm_map(corpus, content_transformer(tolower)) # Convert to lowercase
  corpus <- tm_map(corpus, removePunctuation)           # Remove punctuation
  corpus <- tm_map(corpus, removeNumbers)               # Remove numbers
  corpus <- tm_map(corpus, removeWords, stopwords("en")) # Remove stopwords
  return(corpus)
}

# Preprocess both texts
democrat_corpus <- preprocess_text(democrat)
republic_corpus <- preprocess_text(republic)
```

```{r}
# create matrix
democrat_tdm <- TermDocumentMatrix(democrat_corpus)
republic_tdm <- TermDocumentMatrix(republic_corpus)


# Convert to matrix and calculate word frequencies
democrat_matrix <- as.matrix(democrat_tdm)
republic_matrix <- as.matrix(republic_tdm)


democrat_freq <- sort(rowSums(democrat_matrix))
republic_freq <- sort(rowSums(republic_matrix))
```

```{r}
# visualize for democrat
wordcloud(names(democrat_freq), democrat_freq,
          max.words = 30, colors = brewer.pal(10, "Dark2"))

# visualize for republic
wordcloud(names(republic_freq), republic_freq,
          max.words = 30, colors = brewer.pal(10, "Dark2"))
```
